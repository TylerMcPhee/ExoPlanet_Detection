{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6646b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.fftpack import fft\n",
    "import seaborn as sns\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import cv2\n",
    "\n",
    "import Models \n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8d5d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data\n",
    "\n",
    "# data = pd.read_csv(csv_path)\n",
    "# zip_path = \"kepler-labelled-time-series-data.zip\"\n",
    "# base_dir = os.getcwd()\n",
    "# csv_path = os.path.join(base_dir, zip_path)\n",
    "\n",
    "# with zipfile.ZipFile(csv_path) as z:\n",
    "#     with z.open(\"exoTrain.csv\") as f:\n",
    "#         data = pd.read_csv(f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = data.iloc[:, 1:]  # all columns except the first \n",
    "y = data.iloc[:, 0]   # the first column is the target\n",
    "\n",
    "# Split into 80% train, 20% test\n",
    "# Stratify helps with imbalananced datasets because it helps maintain the same class distribution in both the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b00870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to np array\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "\n",
    "\n",
    "#get the Label column and delate the class column and rescale\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "y_train = (y_train-min(y_train))/(max(y_train)-min(y_train))\n",
    "y_test = (y_test-min(y_test))/(max(y_test)-min(y_test))\n",
    "\n",
    "X_train = np.delete(X_train,1,1)\n",
    "X_test = np.delete(X_test,1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9b63f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Data\n",
    "#print the light curve\n",
    "time = np.arange(len(X_train[0])) * (36/60)  # time in hours\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.title('Flux of star 10 with confirmed planet')\n",
    "plt.ylabel('Flux')\n",
    "plt.xlabel('Hours')\n",
    "plt.plot( time , X_train[10] )     #change the number to plot what you want\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2535378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize\n",
    "norm_X_train = X_train / np.linalg.norm(X_train, axis=1, keepdims=True)\n",
    "norm_X_test = X_test / np.linalg.norm(X_test, axis=1, keepdims=True)\n",
    "\n",
    "#Smooth data\n",
    "smooth_X_train = gaussian_filter1d(norm_X_train,5,1,mode= 'reflect')\n",
    "smooth_X_test = gaussian_filter1d(norm_X_test,5,1,mode= 'reflect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0030d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph smooth data\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.title('Flux of star 10 with confirmed planet, smoothed')\n",
    "plt.ylabel('Flux')\n",
    "plt.xlabel('Hours')\n",
    "plt.plot(time , smooth_X_train[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b2f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply FFT to smoothed data\n",
    "FFT_X_train = np.abs(fft(smooth_X_train))\n",
    "FFT_X_test = np.abs(fft(smooth_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ca1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot star frequency spectrum\n",
    "frequency = np.arange(len(X_train[1000])) * (1/(36.0*60.0))\n",
    "len_seq = len(FFT_X_train[0])\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.title('flux of star 1 ( with confirmed planet ) in domain of frequencies')\n",
    "plt.ylabel('Abs value of FFT result')\n",
    "plt.xlabel('Frequency')\n",
    "plt.plot(frequency, FFT_X_train[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587093bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more of the undersamples data\n",
    "rm = RandomOverSampler(sampling_strategy=0.5)\n",
    "overSamp_X_train, overSamp_y_train = rm.fit_resample(FFT_X_train, y_train)\n",
    "\n",
    "#recap dataset after oversampling\n",
    "print(\"After oversampling, counts of label '1': {}\".format(sum(overSamp_y_train==1)))\n",
    "print(\"After oversampling, counts of label '0': {}\".format(sum(overSamp_y_train==0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape data for CNN\n",
    "overSamp_X_train = np.asarray(overSamp_X_train)\n",
    "FFT_X_test = np.asarray(FFT_X_test)\n",
    "\n",
    "overSamp_X_train_cnn = overSamp_X_train.reshape((overSamp_X_train.shape[0], overSamp_X_train.shape[1], 1))\n",
    "FFT_X_test_cnn = FFT_X_test.reshape((FFT_X_test.shape[0], FFT_X_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ff7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create F.C.N model and run it\n",
    "model = Models.FCN_model(len_seq)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(overSamp_X_train_cnn, overSamp_y_train , epochs=10, batch_size = 10, validation_data=(FFT_X_test_cnn, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d6171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "#acc_val = history.history['val_accuracy']\n",
    "epochs = range(1, len(acc)+1)\n",
    "plt.plot(epochs, acc, 'b', label='accuracy_train')\n",
    "#plt.plot(epochs, acc_val, 'g', label='accuracy_val')\n",
    "plt.title('accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('value of accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "loss = history.history['loss']\n",
    "#loss_val = history.history['val_loss']\n",
    "epochs = range(1, len(acc)+1)\n",
    "plt.plot(epochs, loss, 'b', label='loss_train')\n",
    "#plt.plot(epochs, loss_val, 'g', label='loss_val')\n",
    "plt.title('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('value of loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8096917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the test set and plot results\n",
    "y_test_pred = model.predict(FFT_X_test_cnn)\n",
    "y_test_pred = (y_test_pred > 0.5)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"accuracy : \", accuracy)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred, target_names=[\"NO exoplanet confirmed\",\"YES exoplanet confirmed\"]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
